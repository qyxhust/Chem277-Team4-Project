{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be added in EDA_and_Data_Curation.ipynb after data cleaning cell\n",
    "# calculate weights for combined loss func\n",
    "# get df of just beta values \n",
    "def get_loss_weights(df):\n",
    "    '''\n",
    "    Calculates weights for loss function terms based on inverse variance of beta values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame that includes the columns \"AD_beta\", \"PD_beta\", \"FTD_beta\", \"ALS_beta\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ad_wt, pd_wt, ftd_wt, als_wt : weights for each component of the combined loss function\n",
    "    '''\n",
    "\n",
    "    betas = df[[\"AD_beta\", \"PD_beta\", \"FTD_beta\", \"ALS_beta\"]]\n",
    "\n",
    "    # get variance of beta values for each disease \n",
    "    variances_by_disease = betas.var()\n",
    "\n",
    "    # calculate inverse variance to use as weight\n",
    "    ad_wt = 1/variances_by_disease[\"AD_beta\"]\n",
    "    pd_wt = 1/variances_by_disease[\"PD_beta\"]\n",
    "    ftd_wt = 1/variances_by_disease[\"FTD_beta\"]\n",
    "    als_wt = 1/variances_by_disease[\"ALS_beta\"]\n",
    "\n",
    "    return ad_wt, pd_wt, ftd_wt, als_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c905ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be added in def_train() in train.py\n",
    "# Total loss is the sum of the individual task losses\n",
    "total_loss = get_loss_weights(features_df)[0]*loss_ad + get_loss_weights(features_df)[1]*loss_pd + get_loss_weights(features_df)[2]*loss_ftd + get_loss_weights(features_df)[3]*loss_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec60602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter optimization using itertools grid search\n",
    "# to be added to main() in train.py\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import itertools\n",
    "\n",
    "# define parameter space (learning rate, weight decay, dropout rate, hidden channels, attn heads)\n",
    "# these are based on the original settings in train.py\n",
    "param_grid = {\n",
    "    'Learning_Rate' : [0.01, 0.005, 0.001], \n",
    "    'Hidden_Channels' : [64, 128],\n",
    "    'Attention_Heads': [4, 8],\n",
    "    'Dropout_Rate' : [0.3, 0.6],\n",
    "    'Weight_Decay' : [5e-4, 5e-3]\n",
    "    }\n",
    "\n",
    "base_settings = {'Epochs': 300} # based on original value in train.py\n",
    "best_loss = float('inf') # initialize with value of +infinity\n",
    "best_params = None\n",
    "\n",
    "for values in itertools.product(param_grid.values()):\n",
    "    point = dict(zip(param_grid.keys(), values))\n",
    "    settings = {base_settings, point}\n",
    "\n",
    "    val_loss = evaluate(model, data, data.val_mask) # calculate validation loss\n",
    "\n",
    "    if val_loss < best_loss: # update best loss and params\n",
    "        best_loss = val_loss\n",
    "        best_params = settings\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best val loss: {best_loss}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
