{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e22ad5",
   "metadata": {},
   "source": [
    "3 Layer GCN\n",
    "layer 1: input size num_features, output size 1st hidden size (try 128), ReLU activation\n",
    "layer 2: input size 1st hidden size (try 128), output size 2nd hidden size (try 64), ReLU activation\n",
    "layer 3: input size 2nd hidden size (try 64), output size num_classes (try 64)\n",
    "layers 4, 5, 6, 7: linear layers for predictions (input size is 64, output size different for each layer)\n",
    "\n",
    "Model is being trained to predict:\n",
    "1) Avg_StdBeta_weighted_AD (protein assoc w disease progression/severity, for regression)\n",
    "2) Sig_pos_AD, Sig_neg_AD COMBINED into one binary column (both =1 or 0) (sig pos/neg assoc w disease status, for clasification)\n",
    "3) Combine Sig_pos_AD, Sig_neg_AD, Avg_StdBeta_weighted_AD to identify protein mechanistic role (classification)\n",
    "\n",
    "Start w AD for now, then expand to PD/FTD later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57fb295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devle/miniconda3/envs/277B_final_project/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import random\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7cad2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: create the PPI graph\n",
    "\n",
    "# load in nodes and edges\n",
    "nodes = pd.read_csv(\"nodes.csv\")\n",
    "edges = pd.read_csv(\"edges.csv\")\n",
    "\n",
    "# get edge indices as np array\n",
    "edge_indices_np = edges[['src', 'dst']].values\n",
    "\n",
    "# transpose array so it's in correct format for torch_geometric (2 x num_edges)\n",
    "edge_indices_transposed = edge_indices_np.transpose()\n",
    "\n",
    "# convert to pytorch tensor\n",
    "edge_index_tensor = torch.tensor(edge_indices_transposed, dtype = torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize graph using NetworkX (TO DO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92b4882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5505, 69)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in GNPC data\n",
    "data = pd.read_csv(\"Final_Project_Data.csv\", header=1)\n",
    "data_no_na = data.fillna(0) # convert NAs to 0\n",
    "uniprot_col = data_no_na.iloc[:, 4]\n",
    "numerical_data = data_no_na.iloc[:, 8:]\n",
    "numerical_and_uniprot = pd.concat([uniprot_col, numerical_data], axis=1)\n",
    "data_no_duplicates = numerical_and_uniprot.groupby('UniProt', as_index=False).mean() # calculate mean of all duplicates (same UniProt value)\n",
    "\n",
    "# merge nodes and data\n",
    "proteins = nodes[['index', 'UniProt']]\n",
    "data_nodes_merge = pd.merge(proteins, data_no_duplicates, on = 'UniProt', how = 'left')\n",
    "all_data = data_nodes_merge.sort_values(by='index').reset_index(drop=True) # sort by index\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc04efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create X and Y\n",
    "\n",
    "# select columns to be used for X and Y (make sure to scale!)\n",
    "AD_cols = [col for col in all_data.columns if col.endswith(\"_AD\") or col.startswith(\"AD\")]\n",
    "y_cols = [\"Avg_StdBeta_weighted_AD\", \"Sig_pos_AD\", \"Sig_neg_AD\"]\n",
    "X_cols = [col for col in AD_cols if col not in y_cols]\n",
    "X_np = all_data[X_cols].values # features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_np) # scale X_np\n",
    "\n",
    "x = torch.tensor(X_scaled, dtype=torch.float) # convert to tensor(dtype=torch.float)\n",
    "\n",
    "# Y1: turn Avg_StdBeta_weighted_AD into tensor\n",
    "beta_np = all_data[y_cols].iloc[:, 0].values # Avg_StdBeta as np array\n",
    "beta_re = beta_np.reshape(-1, 1) # reshape to 2D for scaling\n",
    "beta_scaled = scaler.fit_transform(beta_re) # scale beta (being used for regression)\n",
    "y1 = torch.tensor(beta_scaled, dtype=torch.float) # convert to tensor(dtype=torch.float)\n",
    "\n",
    "# Y2: combine Sig_pos_AD and Sig_neg_AD and turn into tensor (dtype=long)\n",
    "sig_cols = all_data[y_cols].iloc[:, 1:]\n",
    "all_data['combined_sig'] = ((all_data['Sig_pos_AD'] == 1) | (all_data['Sig_neg_AD'] == 1)).astype(int) # if either are 1, value in combined col is 1, else 0\n",
    "sig_np = all_data['combined_sig'].values\n",
    "y2 = torch.tensor(sig_np, dtype=torch.long) # convert to tensor(dtype=torch.long)\n",
    "\n",
    "# Y3: classify proteins as drivers, mediators, and bystanders\n",
    "    # driver: Sig_pos_AD/Sig_neg_AD = 1 and StdBeta > 1 (class 0)\n",
    "    # mediator: Sig_pos_AD/Sig_neg_AD = 0 and StdBeta > 1 (class 1)\n",
    "    # bystanders: StdBeta < 1 (class 2)\n",
    "\n",
    "all_data['beta_scaled'] = beta_scaled # add scaled avg std beta values to df\n",
    "all_data['high_beta'] = all_data['beta_scaled'].abs() > 1.0 # 1 is stdev cutoff for Avg_StdBeta bc mean is 0 for scaled data, so 1 is 1 stdev\n",
    "\n",
    "# define three classes (drivers, mediators, bystanders)\n",
    "class_defs = [\n",
    "    # class 0 (driver)\n",
    "    (all_data['combined_sig']) & (all_data['high_beta']),\n",
    "    \n",
    "    # class 1 (mediator)\n",
    "    (~all_data['combined_sig']) & (all_data['high_beta']),\n",
    "\n",
    "    # class 2 (bystander)\n",
    "    (~all_data['high_beta'])\n",
    "]\n",
    "\n",
    "possible_classes = [0,1,2]\n",
    "all_data['mech_role'] = np.select(class_defs, possible_classes) # add col to specify mechanistic role of each protein\n",
    "beta_sig_np = all_data['mech_role'].values\n",
    "y3 = torch.tensor(beta_sig_np, dtype=torch.long) # convert to tensor (dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de62db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate torch_geometric.data.data Data object (IN PROGRESS) - this is from Graph_III.ipynb\n",
    "\n",
    "# create training mask\n",
    "N = all_data.shape[0]\n",
    "training_mask = torch.tensor(np.random.choice([True, False], N, p = [0.3, 0.7]), dtype=torch.bool)\n",
    "# also need validation and test masks?\n",
    "\n",
    "my_data = Data(x = x, y = y, training_mask = training_mask, edge_index = edge_index) # edge_attr = edge_weight\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer GCN with softmax layer for classification (IN PROGRESS)- this is from Graph_III.ipynb\n",
    "\n",
    "class My_GCN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_node_features, n_neuron, n_classes):\n",
    "        super(My_GCN, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(n_node_features, n_neuron)\n",
    "        self.conv2 = GCNConv(n_neuron, n_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        \n",
    "        x1 = self.conv1(x, edge_index, edge_weight = edge_weight)\n",
    "        x2 = F.relu(x1)\n",
    "        x3 = self.conv2(x2, edge_index, edge_weight = edge_weight)\n",
    "        \n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.x3 = x3\n",
    "        \n",
    "        return F.log_softmax(x3, dim = 1)\n",
    "    \n",
    "class FitModel():\n",
    "    \n",
    "    def __init__(self, my_model, learning_rate: float = 0.01):\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(my_model.parameters(), lr = learning_rate)\n",
    "        self.model = my_model\n",
    "        \n",
    "        \n",
    "    def Run(self, data, N_epochs: int = 200):\n",
    "        \n",
    "        lY = len(data.y)\n",
    "        \n",
    "        for n in range(N_epochs):\n",
    "            \n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            out = self.model(data.x, data.edge_index, data.edge_attr)\n",
    "            loss = F.nll_loss(out[data.training_mask], data.y[data.training_mask])\n",
    "            loss.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            Y_pred = out.argmax(dim=1)\n",
    "            \n",
    "            acc    = (Y_pred == data.y).sum()/lY\n",
    "            \n",
    "            if not n % 10:\n",
    "                print(f'epoch: {n:>3} | loss: {loss:.2f} | accuracy: {acc*100:.2f}%' )\n",
    "        \n",
    "        \n",
    "        self.out = out\n",
    "\n",
    "My_Fit = FitModel(my_model, 0.0001)\n",
    "My_Fit.Run(my_data)\n",
    "Probs = np.exp(My_Fit.out.detach()).detach() #since we used log softmax\n",
    "Y_pred = Probs.argmax(dim=1)\n",
    "acc    = (Y_pred == my_data.y).sum()/N\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "277B_final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
